{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surface import grammar\n",
    "from surface import converter\n",
    "from surface.utils import set_parse, get_parse\n",
    "from collections import defaultdict\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we initialize the training and the test file to a variable, the files can be downloaded from the SRST 19 page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"/home/adaamko/data/UD-train/ru_gsd-ud-train.conllu\"\n",
    "TEST_FILE = \"/home/adaamko/data/T1-test/ru_filtered_lines-fix.conllu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the two static grammars (the first corresponds to the subgraphs from the ud trees, the second is the fallback grammar, where each rule is binary)\n",
    "\n",
    "Later, the dynamic grammars are generated from these ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar.train_subgraphs(TRAIN_FILE, TEST_FILE)\n",
    "grammar.train_edges(TRAIN_FILE, TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBGRAPH_GRAMMAR_FILE = \"train_subgraphs\"\n",
    "EDGE_GRAMMAR_FILE = \"train_edges\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract the graphs from the conll format (conversion from conll to isi), and the rules that use the <strong>lin</strong> feature.\n",
    "\n",
    "The rules are for incorporating the <strong>lin</strong> feature, so we can dynamically delete every rule the contradicts the linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules, _ = converter.extract_rules(TEST_FILE)\n",
    "graphs, _, id_graphs= converter.convert(TEST_FILE)\n",
    "_, sentences, _ = converter.convert(TEST_FILE)\n",
    "conll = grammar.get_conll_from_file(TEST_FILE)\n",
    "id_to_parse = {}\n",
    "stops = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run through the sentences and call the <strong>alto</strong> parser to generate the derivation and map the ud representation to string.\n",
    "\n",
    "The alto can be downloaded from [bitbucket](https://bitbucket.org/tclup/alto/downloads/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sen_id in range(0, len(rules)):\n",
    "    print(sen_id)\n",
    "    try:\n",
    "        grammar_fn = open('dep_grammar_spec.irtg', 'w') \n",
    "        grammar.generate_grammar(SUBGRAPH_GRAMMAR_FILE, rules[sen_id], grammar_fn)\n",
    "        grammar.generate_terminal_ids(conll[sen_id], grammar_fn)\n",
    "        grammar_fn.close()\n",
    "        set_parse(\"ewt_ones\", id_graphs[sen_id])\n",
    "        !timeout 70 java -Xmx32G -cp alto-2.3.6-SNAPSHOT-all.jar de.up.ling.irtg.script.ParsingEvaluator ewt_ones -g dep_grammar_spec.irtg -I ud -O string=toString -o surface_eval_ewt\n",
    "        text_parse, conll_parse = get_parse(\"surface_eval_ewt\", conll[sen_id])\n",
    "        id_to_parse[sen_id] = (text_parse, conll_parse)\n",
    "    except StopIteration:\n",
    "        print(\"stop iteratioin\")\n",
    "        stops.append(sen_id)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then iterate through the sentences that took too long to parse with the original grammar, and switch to the binary grammar for faster results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sen_id in stops:\n",
    "    grammar_fn = open('dep_grammar_edges.irtg', 'w') \n",
    "    grammar.generate_grammar(EDGE_GRAMMAR_FILE, rules[sen_id], grammar_fn)\n",
    "    grammar.generate_terminal_ids(conll[sen_id], grammar_fn)\n",
    "    grammar_fn.close()\n",
    "    set_parse(\"ewt_ones\", id_graphs[sen_id])\n",
    "    !java -Xmx32G -cp alto-2.3.6-SNAPSHOT-all.jar de.up.ling.irtg.script.ParsingEvaluator ewt_ones -g dep_grammar_edges.irtg -I ud -O string=toString -o surface_eval_ewt\n",
    "    text_parse, conll_parse = get_parse(\"surface_eval_ewt\", conll[sen_id])\n",
    "    id_to_parse[sen_id] = (text_parse, conll_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/adaamko/data/test-results/ru_filtered_lines-fix.conllu\" , \"w\") as f:\n",
    "    for i in id_to_parse:\n",
    "        conll_f = id_to_parse[i][1]\n",
    "        for line in conll_f:\n",
    "            f.write(str(line) + \"\\t\")\n",
    "            f.write(\"\\t\".join(conll_f[line]))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.to_tokenized_output(\"test-results-inflected/\", \"tokenized_test_results/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}